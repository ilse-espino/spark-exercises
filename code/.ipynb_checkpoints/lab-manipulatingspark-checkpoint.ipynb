{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDDs and DataFrames\n",
    "\n",
    "* We will use the same datasets that we saw in class to practice performing operations on Data_Frames and RDD's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Toshiba.mshome.net:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is creating a spark context which is an abstraction of a cluster\n",
    "# this is creating a spark context which is an abstraction of a cluster\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "\n",
    "sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create an RDD using sc.parallelize() containing a list of list. Each internal list should be made in the form [your_name, age, bootcamp_location, background studies] . For example [Pedro, 27, Lisbon, Physics]. Create 5 people in this RDD (can be your colleagues for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is making an RDD from a python list of lists.\n",
    "\n",
    "data = sc.parallelize([[\"Ilse\", 26, \"Berlin\", \"Engineer\"], [\"Sergio\", 31, \"no bootcamp\", \"Engineer\"], [\"Pedro\", 27, \"Lisbon\", \"Physics\"], [\"Robert\", 28, \"Berlin\", \"idk\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of elements in your list\n",
    "\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ilse', 26, 'Berlin', 'Engineer'],\n",
       " ['Sergio', 31, 'no bootcamp', 'Engineer'],\n",
       " ['Pedro', 27, 'Lisbon', 'Physics'],\n",
       " ['Robert', 28, 'Berlin', 'idk']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return all the elements in your list (which method is the best to apply this on an RDD?)\n",
    "\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RDD' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4ada105b8f42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# would the method .show() work? briefly explain.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RDD' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "# would the method .show() work? briefly explain.\n",
    "\n",
    "\"\"\"no, we need to convert it into a dataframe to show the information\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert your RDD to a spark dataframe, works fine? \n",
    "\n",
    "df = data.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------+--------+\n",
      "|    _1| _2|         _3|      _4|\n",
      "+------+---+-----------+--------+\n",
      "|  Ilse| 26|     Berlin|Engineer|\n",
      "|Sergio| 31|no bootcamp|Engineer|\n",
      "| Pedro| 27|     Lisbon| Physics|\n",
      "|Robert| 28|     Berlin|     idk|\n",
      "+------+---+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now try running again the show method, works?\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same RDD as above but directly using the Row method. save it to a variable called data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run the following commands, what is the difference?\n",
    "df = data.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets now create a more complex structure. Use the same initial RDD as above (the first one I asked you to create)\n",
    "# but now I want the last field to be a list of strings, where each element represents a country the person has lived i\n",
    "# you can make up countries for your colleagues if you are unsure, or use this as a opportunity to talk to them :) \n",
    "\n",
    "# store the result in complex_data variable\n",
    "\n",
    "complex_data = sc.parallelize([[\"Ilse\", 26, \"Berlin\", [\"Mexico\", \"France\", \"Germany\", \"Belgium\"]], [\"Sergio\", 31, \"no bootcamp\", [\"Mexico\", \"Belgium\", \"Germany\"]], [\"Pedro\", 27, \"Lisbon\", [\"Portugal\"]], [\"Robert\", 28, \"Berlin\", [\"Hungary\", \"Germany\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------+--------------------+\n",
      "|    _1| _2|         _3|                  _4|\n",
      "+------+---+-----------+--------------------+\n",
      "|  Ilse| 26|     Berlin|[Mexico, France, ...|\n",
      "|Sergio| 31|no bootcamp|[Mexico, Belgium,...|\n",
      "| Pedro| 27|     Lisbon|          [Portugal]|\n",
      "|Robert| 28|     Berlin|  [Hungary, Germany]|\n",
      "+------+---+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now run this command and voil√†!\n",
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Manipulating Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#create a spark session called \"soccer players lab\" as we did in class\n",
    "\n",
    "spark = SparkSession.builder.appName(\"soccer players lab\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+--------------------+------------------+-------------------+------+------+\n",
      "| id|player_api_id|         player_name|player_fifa_api_id|           birthday|height|weight|\n",
      "+---+-------------+--------------------+------------------+-------------------+------+------+\n",
      "|  1|       505942|  Aaron Appindangoye|            218353|1992-02-29 00:00:00|182.88|   187|\n",
      "|  2|       155782|     Aaron Cresswell|            189615|1989-12-15 00:00:00|170.18|   146|\n",
      "|  3|       162549|         Aaron Doran|            186170|1991-05-13 00:00:00|170.18|   163|\n",
      "|  4|        30572|       Aaron Galindo|            140161|1982-05-08 00:00:00|182.88|   198|\n",
      "|  5|        23780|        Aaron Hughes|             17725|1979-11-08 00:00:00|182.88|   154|\n",
      "|  6|        27316|          Aaron Hunt|            158138|1986-09-04 00:00:00|182.88|   161|\n",
      "|  7|       564793|          Aaron Kuhl|            221280|1996-01-30 00:00:00|172.72|   146|\n",
      "|  8|        30895|        Aaron Lennon|            152747|1987-04-16 00:00:00| 165.1|   139|\n",
      "|  9|       528212|        Aaron Lennox|            206592|1993-02-19 00:00:00| 190.5|   181|\n",
      "| 10|       101042|       Aaron Meijers|            188621|1987-10-28 00:00:00|175.26|   170|\n",
      "| 11|        23889|       Aaron Mokoena|             47189|1980-11-25 00:00:00|182.88|   181|\n",
      "| 12|       231592|          Aaron Mooy|            194958|1990-09-15 00:00:00|175.26|   150|\n",
      "| 13|       163222|      Aaron Muirhead|            213568|1990-08-30 00:00:00|187.96|   168|\n",
      "| 14|        40719|        Aaron Niguez|            183853|1989-04-26 00:00:00|170.18|   143|\n",
      "| 15|        75489|        Aaron Ramsey|            186561|1990-12-26 00:00:00| 177.8|   154|\n",
      "| 16|       597948|       Aaron Splaine|            226014|1996-10-13 00:00:00|172.72|   163|\n",
      "| 17|       161644|Aaron Taylor-Sinc...|            213569|1991-04-08 00:00:00|182.88|   176|\n",
      "| 18|        23499|     Aaron Wilbraham|              2335|1979-10-21 00:00:00| 190.5|   159|\n",
      "| 19|       120919|   Aatif Chahechouhe|            187939|1986-07-02 00:00:00|175.26|   150|\n",
      "| 20|        46447|           Abasse Ba|            156626|1976-07-12 00:00:00|187.96|   185|\n",
      "+---+-------------+--------------------+------------------+-------------------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the line of code below to read the players dataset\n",
    "# load the players csv into a datafrane called players\n",
    "\n",
    "players = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../datasets/player.csv\")\n",
    "\n",
    "players.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+--------------------+------------------+-------------------+------+------+\n",
      "|  id|player_api_id|         player_name|player_fifa_api_id|           birthday|height|weight|\n",
      "+----+-------------+--------------------+------------------+-------------------+------+------+\n",
      "|5453|        97226|          Juan Quero|            171126|1984-10-17 00:00:00|157.48|   117|\n",
      "|7258|        29587|        Maxi Moralez|            183895|1987-02-27 00:00:00|160.02|   126|\n",
      "|2612|       103139|    Diego Buonanotte|            170719|1988-04-19 00:00:00|160.02|   123|\n",
      "|2857|       278917|         Edgar Salli|            205753|1992-08-17 00:00:00|162.56|   141|\n",
      "|1084|        30691|         Bakari Kone|            137113|1981-09-17 00:00:00|162.56|   134|\n",
      "|8686|        46891|       Quentin Othon|            179794|1988-03-27 00:00:00|162.56|   141|\n",
      "|9441|       364813|      Samuel Asamoah|            213228|1994-03-23 00:00:00|162.56|   132|\n",
      "|3446|       215412|        Fouad Rachid|            201504|1991-11-15 00:00:00|162.56|   126|\n",
      "| 832|        11327|      Anthony Deroin|             51121|1979-03-15 00:00:00|162.56|   146|\n",
      "|3584|       143752|Frederic Sammaritano|            187988|1986-03-23 00:00:00|162.56|   146|\n",
      "|6212|       193441|     Lorenzo Insigne|            198219|1991-06-04 00:00:00|162.56|   130|\n",
      "|8263|        46384|        Pablo Piatti|            183899|1989-03-31 00:00:00|162.56|   139|\n",
      "| 317|       664961|         Aldo Kalulu|            230079|1996-01-21 00:00:00| 165.1|   126|\n",
      "| 328|        45220|Alejandro Daro Gomez|            143076|1988-02-15 00:00:00| 165.1|   150|\n",
      "|2947|       352394|          Elson Hooi|            209447|1991-10-01 00:00:00| 165.1|   141|\n",
      "| 993|        38842|         Arthur Boka|             49116|1983-04-02 00:00:00| 165.1|   143|\n",
      "|3648|        36552|        Gaetan Krebs|            163662|1985-11-18 00:00:00| 165.1|   139|\n",
      "|5992|       111190|               Laure|            188930|1985-03-22 00:00:00| 165.1|   150|\n",
      "| 355|       306158| Aleksander Jagiello|            213157|1995-02-02 00:00:00| 165.1|   132|\n",
      "|1480|       163840|             Caetano|            199931|1991-04-20 00:00:00| 165.1|   123|\n",
      "+----+-------------+--------------------+------------------+-------------------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort the dataframe by height of players, in ascending order (if Peter Crouch comes first, you did it wrong :P )\n",
    "\n",
    "players.sort(\"height\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now read the player attributes dataframe like we did in class. store it inside a variable called player_attributes\n",
    "\n",
    "player_attributes = spark.read\\\n",
    "                         .format(\"csv\")\\\n",
    "                         .option(\"header\", \"true\")\\\n",
    "                         .load(\"../datasets/player_attributes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- player_fifa_api_id: string (nullable = true)\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- overall_rating: string (nullable = true)\n",
      " |-- potential: string (nullable = true)\n",
      " |-- preferred_foot: string (nullable = true)\n",
      " |-- attacking_work_rate: string (nullable = true)\n",
      " |-- defensive_work_rate: string (nullable = true)\n",
      " |-- crossing: string (nullable = true)\n",
      " |-- finishing: string (nullable = true)\n",
      " |-- heading_accuracy: string (nullable = true)\n",
      " |-- short_passing: string (nullable = true)\n",
      " |-- volleys: string (nullable = true)\n",
      " |-- dribbling: string (nullable = true)\n",
      " |-- curve: string (nullable = true)\n",
      " |-- free_kick_accuracy: string (nullable = true)\n",
      " |-- long_passing: string (nullable = true)\n",
      " |-- ball_control: string (nullable = true)\n",
      " |-- acceleration: string (nullable = true)\n",
      " |-- sprint_speed: string (nullable = true)\n",
      " |-- agility: string (nullable = true)\n",
      " |-- reactions: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- shot_power: string (nullable = true)\n",
      " |-- jumping: string (nullable = true)\n",
      " |-- stamina: string (nullable = true)\n",
      " |-- strength: string (nullable = true)\n",
      " |-- long_shots: string (nullable = true)\n",
      " |-- aggression: string (nullable = true)\n",
      " |-- interceptions: string (nullable = true)\n",
      " |-- positioning: string (nullable = true)\n",
      " |-- vision: string (nullable = true)\n",
      " |-- penalties: string (nullable = true)\n",
      " |-- marking: string (nullable = true)\n",
      " |-- standing_tackle: string (nullable = true)\n",
      " |-- sliding_tackle: string (nullable = true)\n",
      " |-- gk_diving: string (nullable = true)\n",
      " |-- gk_handling: string (nullable = true)\n",
      " |-- gk_kicking: string (nullable = true)\n",
      " |-- gk_positioning: string (nullable = true)\n",
      " |-- gk_reflexes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "player_attributes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used to be a goalkeeper growing up so lets analyze goalkeepers . Sort the players by goal keeper diving in descending order\n",
    "# this should allows us to obtain the goalkeepers only... and Neymar\n",
    "\n",
    "goal_keepers = player_attributes.sort(\"gk_diving\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create a new sparkdataframe which only contains players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a score of the weighted average of the goalkeeping skills goal it gk_grade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's select young talents only, so I want the top 40 goalkeepers from the latest season who are no older than 26\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort them by descending gk_grade and tell me who Benfica should hire for the goal :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who do you think was the best goalkeeper of all time? For me my hero was Fabien Barthez from Manchester United\n",
    "\n",
    "# find him in the dataset and calculate his gk_score over the years. How did it evolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: want to practice acumulators? from your top goalkeepers tier them in height bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exploring SparkSql - soccer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's practice a similar analysis but with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using the initial object from the CSV file create a temporary view so we can perform SQL query on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a basic select * query of all fields of your new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a SQL query thart only returns that players that have \"suarez\" in their name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any players with the same birthday as yours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the players attributed table into a sql temporary table as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tough challenge: let's build a mini product: it allows you to select two players, a feature of skill and the result\n",
    "# is a table where you can see side by side, in the years that both players played how each player evolved in that feature\n",
    "\n",
    "# shall we do a classic Messi vs Ronaldo?\n",
    "\n",
    "name_1 = \"Lionel Messi\"\n",
    "name_2 = \"Cristiano Ronaldo\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
